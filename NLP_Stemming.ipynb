{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOMJfa1QkjcGJp3VfUTDYtd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["stemming is the process of reducing a word to its root or base form, called the \"stem.\" The idea is to strip away prefixes and suffixes to obtain a word's core meaning, which can help reduce variations of a word to a single form. For instance, words like \"running,\" \"runner,\" and \"ran\" may all be reduced to the stem \"run.\""],"metadata":{"id":"ttiUn3zvS3eA"}},{"cell_type":"markdown","source":["## Stemming technique 1 - Porter stemming\n","\n","One of the oldest and most commonly used. It's rule-based and reduces words according to predefined suffix-removal rules."],"metadata":{"id":"EKOLoZ0kTHZu"}},{"cell_type":"code","source":["!pip install nltk\n","from nltk.stem import PorterStemmer\n","\n","stemmar = PorterStemmer()\n","\n","words = [\"eating\", \"eats\", \"eat\", \"ate\", \"adjustable\", \"rafting\", \"ability\", \"meeting\"]\n","\n","for word in words:\n","    print(word, \":\", stemmar.stem(word))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I4SAle0FS6KF","executionInfo":{"status":"ok","timestamp":1730020375832,"user_tz":-330,"elapsed":4411,"user":{"displayName":"ankit singh","userId":"04293018571785188855"}},"outputId":"55b45780-45da-4c6d-9aad-86de1743cd8b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n","eating : eat\n","eats : eat\n","eat : eat\n","ate : ate\n","adjustable : adjust\n","rafting : raft\n","ability : abil\n","meeting : meet\n"]}]},{"cell_type":"markdown","source":["## Disadvantage - While using stemming, you may not get the correct word as a result.\n","\n","For example -"],"metadata":{"id":"1_YKK0jrUB5O"}},{"cell_type":"code","source":["stemmar.stem(\"congratulations\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"1CQEhaBwUPyu","executionInfo":{"status":"ok","timestamp":1730020379001,"user_tz":-330,"elapsed":513,"user":{"displayName":"ankit singh","userId":"04293018571785188855"}},"outputId":"dec3c4e9-0577-415e-ad20-4fd99f1b9655"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'congratul'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["# RegexpStemmer class\n","\n","NLTK has RegexpStemmer class with the help of which we can easily implement Regular\n","Expression Stemmer algorithms. It basically takes a single regular expression and removes any\n","prefix or suffix that matches the expression. Let us see an example"],"metadata":{"id":"elWgaupaU3MN"}},{"cell_type":"code","source":["from nltk.stem import RegexpStemmer\n","\n","regexp = RegexpStemmer('ing$|s$|e$|able$', min=4)\n","\n","# if dollar($) is written after the word, then it will remove that suffix from provided word.\n","# if dollar($) is written before the word, then it will remove that prefix from provided word.\n","\n","regexp.stem(\"creates\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"mR_0h0n5AaSt","executionInfo":{"status":"ok","timestamp":1730020381477,"user_tz":-330,"elapsed":631,"user":{"displayName":"ankit singh","userId":"04293018571785188855"}},"outputId":"d439f449-6ade-4cbc-f08b-abdf8cfb6cbc"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'create'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["regexp.stem(\"create\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"9aW27zOsBUuv","executionInfo":{"status":"ok","timestamp":1730020384427,"user_tz":-330,"elapsed":539,"user":{"displayName":"ankit singh","userId":"04293018571785188855"}},"outputId":"a3184b8a-b615-4f9c-9855-bbd6159348dd"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'creat'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["## SnowBall Stemmer -\n","\n","The Snowball Stemmer, also known as the Porter2 Stemmer, is an advanced and versatile stemming algorithm used in natural language processing. It is an improvement upon the original Porter Stemmer, developed by Martin Porter, and is designed to handle the morphological complexities of various languages more accurately and consistently."],"metadata":{"id":"z0_n9tjrPP7H"}},{"cell_type":"code","source":["from nltk.stem import SnowballStemmer\n","\n","snowball = SnowballStemmer('english')\n","\n","for word in words:\n","    print(word, \"--->\", snowball.stem(word))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X4XoOfoGPbsp","executionInfo":{"status":"ok","timestamp":1730020387506,"user_tz":-330,"elapsed":526,"user":{"displayName":"ankit singh","userId":"04293018571785188855"}},"outputId":"baf1dd68-0ead-4018-d216-f57b562519a3"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["eating ---> eat\n","eats ---> eat\n","eat ---> eat\n","ate ---> ate\n","adjustable ---> adjust\n","rafting ---> raft\n","ability ---> abil\n","meeting ---> meet\n"]}]},{"cell_type":"markdown","source":["### difference between porter stemmer and snowball stemmer -"],"metadata":{"id":"umTfq6gZQNtY"}},{"cell_type":"code","source":["stemmar.stem('fairly'), snowball.stem('fairly')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gkHfdwiTQULR","executionInfo":{"status":"ok","timestamp":1730020527334,"user_tz":-330,"elapsed":492,"user":{"displayName":"ankit singh","userId":"04293018571785188855"}},"outputId":"f6b5e5e4-37a7-40ae-f03a-14ff22147e8f"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["('fairli', 'fair')"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["# even snowball stemmer gives incorrect results\n","\n","snowball.stem('goes')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"BfOuHOJKQgMO","executionInfo":{"status":"ok","timestamp":1730020920865,"user_tz":-330,"elapsed":499,"user":{"displayName":"ankit singh","userId":"04293018571785188855"}},"outputId":"fd32da65-8a66-407b-9f19-cfb5d22a6a90"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'goe'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["## these techniques cannot be used for usecases like chatbots,\n","# so we have to go for lemmatization"],"metadata":{"id":"8A0obh6cSKws"}},{"cell_type":"code","source":[],"metadata":{"id":"aAajxCPXSVJV"},"execution_count":null,"outputs":[]}]}